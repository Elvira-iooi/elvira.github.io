<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[MPI的容器化封装]]></title>
      <url>/2017/11/25/MPI%E7%9A%84%E5%AE%B9%E5%99%A8%E5%8C%96%E5%B0%81%E8%A3%85/</url>
      <content type="html"><![CDATA[<pre><code>基于Docker的HPC平台
问题：
1、mpirun hydra；
2、docker封装openmpi、mpich、数学库，若干个版本；
3、docker之间通信网络：通过与主机的bridge；或者，docker之间创建虚拟网络。
</code></pre><p>————————————————————————————————————————</p>
<h2 id="0、知识准备"><a href="#0、知识准备" class="headerlink" title="0、知识准备"></a>0、知识准备</h2><h6 id="并行计算基础（六种实现手段）"><a href="#并行计算基础（六种实现手段）" class="headerlink" title="*并行计算基础（六种实现手段）"></a>*并行计算基础（六种实现手段）</h6><a id="more"></a>
<h3 id="一-MPI的认识"><a href="#一-MPI的认识" class="headerlink" title="(一)MPI的认识"></a>(一)MPI的认识</h3><pre><code>       MPI：message passing interface，即信息传递接口，包含协议和语义说明。它是一个跨语言的通讯协议，支持点对点和广播，在进程级实现并行计算。（http://mpi-forum.org/）
MPI的模型叫做SPMD，single program multiple data，即运行同一个程序，但是处理不同的数据。进程的行为由通讯域（communication world）和该通讯域下的id（rank id）所决定。
       *注：MPI可扩展性好，且控制精细度高；但它的编程模型复杂，必须精雕细琢：
            (1).需要分析及划分应用程序问题，并将问题映射到分布式进程集合；
            (2).需要解决通信延迟大和负载不平衡的两个主要问题；
            (3).调试MPI程序麻烦；
            (4).MPI程序可靠性差，一个进程出问题，整个程序将错误。        
       实现：OpenMPI：https://www.open-mpi.org/
             MPICH：https://www.mpich.org/
       安装及Hellow：移步：https://greenshd.github.io/ （目前只安装了mpich，后续更新openmpi）
       MPI程序编译环境：
            * 传统语言（C，C++，Fortran）编译器 + 符合MPI标准的库
       MPI程序编译执行的流程是：
            ===&gt;mpicc -o 编译mpi程序，将mpi.f头文件加载到程序中，形成可执行并行程序；
            ===&gt;通过mpirun脚本建立并行环境，分配节点/进程rank

      mpirun：shell脚本，由hydra实现。
      hydra：进程管理器（Process Manager，PM）利用ssh、rsh、pbs、slurm和sge等工具部署并运行程序。相对于mpd较为轻量——不用额外启动服务器端，不用进行复杂的服务器配置，只需写一个hosts文件即可。
</code></pre>]]></content>
      
        <categories>
            
            <category> MPI </category>
            
        </categories>
        
        
        <tags>
            
            <tag> MPI </tag>
            
            <tag> Docker </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[install mpich]]></title>
      <url>/2017/11/25/install-mpich/</url>
      <content type="html"><![CDATA[<h3 id="实验环境："><a href="#实验环境：" class="headerlink" title="实验环境："></a>实验环境：</h3><pre><code>Ubuntu 16.04   64bit  已安装apt-get、wget、vi/vim、gcc、g++
三台主机：114.212.82.116
        114.212.82.171
        114.212.83.36
        用户名：apple   密码：******
</code></pre><h3 id="0、连网（登bras）"><a href="#0、连网（登bras）" class="headerlink" title="0、连网（登bras）"></a>0、连网（登bras）</h3><pre><code>命令：curl http://p.nju.edu.cn/portal_io/login -d username=xxxx -d password=xxxxx
</code></pre><a id="more"></a>
<h3 id="1、下载源文件"><a href="#1、下载源文件" class="headerlink" title="1、下载源文件"></a>1、下载源文件</h3><pre><code>镜像网站，下载比较快：http://www.mpich.org/static/downloads/3.2.1/
官方网站，下载比较慢：http://www.mpich.org/downloads/
命令：wget http://www.mpich.org/static/downloads/3.2.1/mpich-3.2.1.tar.gz
</code></pre><h3 id="2、解压源文件"><a href="#2、解压源文件" class="headerlink" title="2、解压源文件"></a>2、解压源文件</h3><pre><code>在home/apple下创建安装文件夹：mkdir mpich_install
解压mpich压缩包到该文件夹下：sudo tar -zxvf mpich-3.2.1.tar.gz -C mpich_install
</code></pre><h3 id="3、编译与安装"><a href="#3、编译与安装" class="headerlink" title="3、编译与安装"></a>3、编译与安装</h3><pre><code>在home/apple下创建安装路径文件夹：mkdir mpich （注：pwd查看当前路径）
进入mpich_install目录，使用ls命令查看便可发现多出了一个mpich-3.2.1目录
进入mpich-3.2.1目录，进行软件配置与检查，这里只设置安装目录即可。命令：
./configure -prefix=/home/apple/mpich （注：prefix参数表示安装路径，即mpich文件夹）
接下来执行make命令编译，make install命令安装；也可make &amp;&amp; make install
</code></pre><h3 id="4、配置环境变量"><a href="#4、配置环境变量" class="headerlink" title="4、配置环境变量"></a>4、配置环境变量</h3><pre><code>编译执行的命令（mpicc、mpirun）是需要添加的，必须添加绝对路径才能正常使用。
修改path，为path添加mpi的bin目录：进入mpich-3.2.1目录 vim ~/.bashrc
在.bashrc文件的末尾添加：export PATH=/home/apple/mpich/bin:$PATH    
然后执行 source ~/.bashrc
echo  $PATH，查看PATH是否发生变化；
注销再登录后，查看bin下的可执行程序：ls /home/apple/mpich/bin
查看命令是否是安装目录下的命令：which mpiexec
</code></pre><h3 id="5、使用mpi命令"><a href="#5、使用mpi命令" class="headerlink" title="5、使用mpi命令"></a>5、使用mpi命令</h3><pre><code>编译MPI程序用mpicc，执行MPI程序用mpiexec。
进入mpich-3.2.1目录下，ls可查看到有一个examples文件夹，进行测试确保安装成功：
mpirun -np 10 ./examples/cpi   （或可以-n）
再进入examples目录下，编译运行hellow：
编译：mpicc -o hellow hellow.c   运行：mpirun -np 4 ./hellow  
</code></pre><h3 id="6、实现各主机间无密码登录"><a href="#6、实现各主机间无密码登录" class="headerlink" title="6、实现各主机间无密码登录"></a>6、实现各主机间无密码登录</h3><pre><code>如需使用MPI在不同的机器上运行程序，一方面可以使用超级用户权限，另一方面，有些情况下我们不能拥有操作系统的超级用户权限，导致不能改动除用户文件夹以外的文件夹。因此，以下步骤可以使普通用户实现mpi程序的编译和多机器运行。
（0）前提：知道三台主机的ip，用户名相同均为apple，并安装了相同版本号的mpich。
（1）检查各个机器的PATH（该步骤在前几个操作中已经提及，此处不再设置）：mpicc —version
得到如下结果即可继续，否则，返回第4步重新设置PATH：
</code></pre><p><img src="/2017/11/25/install-mpich/1.jpg" alt="0"></p>
<pre><code>（2）两两之间设置无password登录:
如果当下是机器apple@u194（IP为114.212.82.116），运行以下命令：ssh-keygen -t rsa
不要输入任何内容，直接回车。运行以下命令：ssh apple@114.212.82.171 mkdir -p .ssh
将会提示输入机器apple@u171（IP为114.212.82.171）的password，输入后，敲击回车;
运行以下命令：
cat .ssh/id_rsa.pub | ssh apple@114.212.82.171 &apos;cat &gt;&gt; .ssh/authorized_keys’
然后登录apple@u171：ssh apple@114.212.82.171
继续运行以下命令：ssh-keygen -t rsa 遇到yes/no，yes；其余情况一律回车；
运行以下命令：
cat .ssh/id_rsa.pub | ssh apple@114.212.82.116 &apos;cat &gt;&gt; .ssh/authorized_keys’
最后运行以下命令，以推出机器apple@u171：exit
完成上面的步骤后，就可以实现apple用户在u194和u171之间免密登录了。
其余主机也是如此设置，但需要注意的是，每台主机的rsa密钥只需生成一次，不要重复设置以免覆盖原有的图案。
</code></pre><h3 id="7、mpi多机器运行"><a href="#7、mpi多机器运行" class="headerlink" title="7、mpi多机器运行"></a>7、mpi多机器运行</h3><pre><code>（0）首先在apple@u171的/home/apple目录下，新建test.c文件，代码如下：
</code></pre><p><img src="/2017/11/25/install-mpich/2.jpg" alt="1"></p>
<pre><code>（1）执行命令mpicc -o test test.c 进行编译，生成可执行文件test
（2）在apple@u36、apple@u171、apple@u194的/home/apple目录下，分别新建一个hosts文件，用来保存三台机器的IP地址，第一行是本机IP，示例如下：（apple@u171下的hosts内容）
</code></pre><p><img src="/2017/11/25/install-mpich/3.jpg" alt="2"></p>
<pre><code>（3）然后将apple@u171中，刚刚编译生成的test，复制到其他机器相同目录下，命令为：
    scp apple@114.212.82.171:/home/apple/test /home/apple
（4）在apple@u171的/home/apple目录下，执行命令：mpirun -n 10 -f /home/apple/hosts ./test
    得到如下结果：
</code></pre><p><img src="/2017/11/25/install-mpich/4.jpg" alt="3"></p>
<h3 id="附："><a href="#附：" class="headerlink" title="附："></a>附：</h3><pre><code>每台机器各个目录下的文件如下所示：
1、apple@u194 （114.212.82.116）
</code></pre><p><img src="/2017/11/25/install-mpich/194.jpg" alt="4"></p>
<pre><code>2、apple@u171 （114.212.82.171）
</code></pre><p><img src="/2017/11/25/install-mpich/171.jpg" alt="5"></p>
<pre><code>3、apple@u36 （114.212.83.36） 
</code></pre><p><img src="/2017/11/25/install-mpich/36.jpg" alt="6"></p>
<pre><code>u171、u194都有2个process，u36只有一个；如果开6个，则每台主机分到2个process。
所以process的分配是和hosts中写的IP顺序有关吗？
</code></pre>]]></content>
      
        
    </entry>
    
  
  
</search>
